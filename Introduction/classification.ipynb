{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "we will predict the probability that a specific data point or entry is in all the classes it can be\n",
    "\n",
    "we will use different properties of flower to predict what species of flower it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "ths dataset seperates flowers into 3 classes of species\n",
    "\n",
    "* setosa\n",
    "* versicolor\n",
    "* virginica\n",
    "\n",
    "the information about each flower is provided as the following:\n",
    "* sepal length\n",
    "* sepal width\n",
    "* petal length\n",
    "* petal width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMN_NAMES = [\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\", \"Species\"] # Pandas needs the headers to make a dataframe\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica'] # species names for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data files are stored in a python module within tensorflow called keras\n",
    "train_path = tf.keras.utils.get_file(\"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
    "\n",
    "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
       "0          6.4         2.8          5.6         2.2        2\n",
       "1          5.0         2.3          3.3         1.0        1\n",
       "2          4.9         2.5          4.5         1.7        2\n",
       "3          4.9         3.1          1.5         0.1        0\n",
       "4          5.7         3.8          1.7         0.3        0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head() # in centimeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train.pop('Species')\n",
    "test_y = test.pop('Species')\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    1\n",
       "2    2\n",
       "3    0\n",
       "4    0\n",
       "Name: Species, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input function\n",
    "there are no epochs and the batch size is larger. We dont create a function in the input function\n",
    "we must create the tensor dataset to be used by tensor flow\n",
    "\n",
    "if the model is training, it repeats and shuffles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    # convert inputs into a tensorflow dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # shuffle and repeat if in training mode\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "\n",
    "    return dataset.batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "# feature columns, loop through all the keys in the training set and append to feature columns\n",
    "\n",
    "my_feature_column = []\n",
    "for key in train.keys(): # get the headers from the CSV file train\n",
    "    my_feature_column.append(tf.feature_column.numeric_column(key=key)) # append the key as a feature column into the tensor\n",
    "print(my_feature_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "we will be using a classification model. We have two main types of model we can use for our purposes. \n",
    "\n",
    "`DNNClassifier` (deep neural network)\n",
    "\n",
    "`LinearClassifier` (operates much like linear regression, we get the probability of being a type rather than a precise value)\n",
    "\n",
    "DNN is the best in this case because we are not certain of a linear relationship in the data\n",
    "so lets go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ahuma\\AppData\\Local\\Temp\\tmpnj94zelq\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ahuma\\\\AppData\\\\Local\\\\Temp\\\\tmpnj94zelq', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_column, \n",
    "    # Two hidden layers of 30 and 10 nodes respectively\n",
    "    hidden_units=[30, 10], \n",
    "    # the model must choose between 3 classes\n",
    "    n_classes=3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ahuma\\AppData\\Local\\Temp\\tmpnj94zelq\\model.ckpt-25000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 25000...\n",
      "INFO:tensorflow:Saving checkpoints for 25000 into C:\\Users\\ahuma\\AppData\\Local\\Temp\\tmpnj94zelq\\model.ckpt.\n",
      "INFO:tensorflow:C:\\Users\\ahuma\\AppData\\Local\\Temp\\tmpnj94zelq\\model.ckpt-25000.data-00000-of-00001\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:C:\\Users\\ahuma\\AppData\\Local\\Temp\\tmpnj94zelq\\model.ckpt-25000.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:C:\\Users\\ahuma\\AppData\\Local\\Temp\\tmpnj94zelq\\model.ckpt-25000.meta\n",
      "INFO:tensorflow:100\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 25000...\n",
      "INFO:tensorflow:loss = 0.09397784, step = 25000\n",
      "INFO:tensorflow:global_step/sec: 273.702\n",
      "INFO:tensorflow:loss = 0.084226206, step = 25100 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.978\n",
      "INFO:tensorflow:loss = 0.10076862, step = 25200 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.819\n",
      "INFO:tensorflow:loss = 0.09143883, step = 25300 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.885\n",
      "INFO:tensorflow:loss = 0.08519288, step = 25400 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.372\n",
      "INFO:tensorflow:loss = 0.09611598, step = 25500 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.776\n",
      "INFO:tensorflow:loss = 0.09333172, step = 25600 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.052\n",
      "INFO:tensorflow:loss = 0.09389512, step = 25700 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.839\n",
      "INFO:tensorflow:loss = 0.102180034, step = 25800 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.99\n",
      "INFO:tensorflow:loss = 0.092003584, step = 25900 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.849\n",
      "INFO:tensorflow:loss = 0.07384719, step = 26000 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.878\n",
      "INFO:tensorflow:loss = 0.09271351, step = 26100 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.456\n",
      "INFO:tensorflow:loss = 0.090400614, step = 26200 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.89\n",
      "INFO:tensorflow:loss = 0.09202655, step = 26300 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.616\n",
      "INFO:tensorflow:loss = 0.091714546, step = 26400 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.765\n",
      "INFO:tensorflow:loss = 0.095226586, step = 26500 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.723\n",
      "INFO:tensorflow:loss = 0.09789306, step = 26600 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.927\n",
      "INFO:tensorflow:loss = 0.097021684, step = 26700 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.105\n",
      "INFO:tensorflow:loss = 0.09454533, step = 26800 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.62\n",
      "INFO:tensorflow:loss = 0.08190017, step = 26900 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.82\n",
      "INFO:tensorflow:loss = 0.083488695, step = 27000 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.145\n",
      "INFO:tensorflow:loss = 0.089058116, step = 27100 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.36\n",
      "INFO:tensorflow:loss = 0.100736916, step = 27200 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.605\n",
      "INFO:tensorflow:loss = 0.087745234, step = 27300 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.863\n",
      "INFO:tensorflow:loss = 0.099350385, step = 27400 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.367\n",
      "INFO:tensorflow:loss = 0.087936975, step = 27500 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.4\n",
      "INFO:tensorflow:loss = 0.10049707, step = 27600 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.355\n",
      "INFO:tensorflow:loss = 0.091677524, step = 27700 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.145\n",
      "INFO:tensorflow:loss = 0.087836176, step = 27800 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.358\n",
      "INFO:tensorflow:loss = 0.093661845, step = 27900 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.423\n",
      "INFO:tensorflow:loss = 0.08953321, step = 28000 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.877\n",
      "INFO:tensorflow:loss = 0.09229787, step = 28100 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.289\n",
      "INFO:tensorflow:loss = 0.09269975, step = 28200 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.742\n",
      "INFO:tensorflow:loss = 0.09452595, step = 28300 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.119\n",
      "INFO:tensorflow:loss = 0.101634115, step = 28400 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.238\n",
      "INFO:tensorflow:loss = 0.092111275, step = 28500 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.894\n",
      "INFO:tensorflow:loss = 0.08781812, step = 28600 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.221\n",
      "INFO:tensorflow:loss = 0.08539432, step = 28700 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.008\n",
      "INFO:tensorflow:loss = 0.07818878, step = 28800 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.015\n",
      "INFO:tensorflow:loss = 0.09826836, step = 28900 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.625\n",
      "INFO:tensorflow:loss = 0.100357, step = 29000 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.141\n",
      "INFO:tensorflow:loss = 0.08998425, step = 29100 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.873\n",
      "INFO:tensorflow:loss = 0.09361069, step = 29200 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.821\n",
      "INFO:tensorflow:loss = 0.09160137, step = 29300 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.146\n",
      "INFO:tensorflow:loss = 0.0930154, step = 29400 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.317\n",
      "INFO:tensorflow:loss = 0.0953536, step = 29500 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.195\n",
      "INFO:tensorflow:loss = 0.09550483, step = 29600 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.173\n",
      "INFO:tensorflow:loss = 0.07979572, step = 29700 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.886\n",
      "INFO:tensorflow:loss = 0.08434795, step = 29800 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.145\n",
      "INFO:tensorflow:loss = 0.07911394, step = 29900 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.61\n",
      "INFO:tensorflow:loss = 0.084629565, step = 30000 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.652\n",
      "INFO:tensorflow:loss = 0.086160235, step = 30100 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.214\n",
      "INFO:tensorflow:loss = 0.08190176, step = 30200 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.637\n",
      "INFO:tensorflow:loss = 0.083725825, step = 30300 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.132\n",
      "INFO:tensorflow:loss = 0.082939625, step = 30400 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.411\n",
      "INFO:tensorflow:loss = 0.094392285, step = 30500 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.144\n",
      "INFO:tensorflow:loss = 0.09465545, step = 30600 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.119\n",
      "INFO:tensorflow:loss = 0.08751071, step = 30700 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.011\n",
      "INFO:tensorflow:loss = 0.073903926, step = 30800 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.611\n",
      "INFO:tensorflow:loss = 0.085566685, step = 30900 (0.281 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 31000...\n",
      "INFO:tensorflow:Saving checkpoints for 31000 into C:\\Users\\ahuma\\AppData\\Local\\Temp\\tmpnj94zelq\\model.ckpt.\n",
      "INFO:tensorflow:C:\\Users\\ahuma\\AppData\\Local\\Temp\\tmpnj94zelq\\model.ckpt-31000.data-00000-of-00001\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:C:\\Users\\ahuma\\AppData\\Local\\Temp\\tmpnj94zelq\\model.ckpt-31000.index\n",
      "INFO:tensorflow:0\n",
      "INFO:tensorflow:C:\\Users\\ahuma\\AppData\\Local\\Temp\\tmpnj94zelq\\model.ckpt-31000.meta\n",
      "INFO:tensorflow:100\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 31000...\n",
      "INFO:tensorflow:Loss for final step: 0.084222004.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x24712659990>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we would like to use a lambda instead of using nested functions for the input function.\n",
    "classifier.train(\n",
    "    input_fn=lambda: input_fn(train, train_y, training=True),\n",
    "    steps=6000 # go through the dataset until 5000 datapoints have been processed\n",
    ")\n",
    "\n",
    "# steps per second is displayed. The lower the loss the better. Current step also displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-07-12T14:10:08\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ahuma\\AppData\\Local\\Temp\\tmpnj94zelq\\model.ckpt-31000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.36600s\n",
      "INFO:tensorflow:Finished evaluation at 2022-07-12-14:10:08\n",
      "INFO:tensorflow:Saving dict for global step 31000: accuracy = 1.0, average_loss = 0.08030086, global_step = 31000, loss = 0.08030086\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 31000: C:\\Users\\ahuma\\AppData\\Local\\Temp\\tmpnj94zelq\\model.ckpt-31000\n",
      "\n",
      "Test set accuracy: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "eval_result = classifier.evaluate(input_fn=lambda:input_fn(test, test_y, training=False))\n",
    "print(f\"\\nTest set accuracy: {eval_result['accuracy']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 1.0, 'average_loss': 0.08030086, 'loss': 0.08030086, 'global_step': 31000}\n"
     ]
    }
   ],
   "source": [
    "print(eval_result)\n",
    "#print(test_y.loc[2])\n",
    "#print(eval_result[2]) # a list of all the different dictionary that represent each element in the eval dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100% accuracy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## making predictions\n",
    "we will make a script to take user input and predict what kind of flower it will be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type numeric values as prompted.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ahuma\\AppData\\Local\\Temp\\tmpnj94zelq\\model.ckpt-31000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prediction is Versicolor, 60.763633251190186%\n",
      "{'logits': array([-0.499649 ,  1.0321745,  0.187227 ], dtype=float32), 'probabilities': array([0.13133524, 0.60763633, 0.26102838], dtype=float32), 'class_ids': array([1], dtype=int64), 'classes': array([b'1'], dtype=object), 'all_class_ids': array([0, 1, 2]), 'all_classes': array([b'0', b'1', b'2'], dtype=object)}\n"
     ]
    }
   ],
   "source": [
    "def input_function(features, batch_size=256):\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "    # create an input with features, with no lables so we can get an answer\n",
    "\n",
    "features = [\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\"]\n",
    "predict = {} # Store the values for whcih we want to predict the class\n",
    "\n",
    "print(\"Please type numeric values as prompted.\")\n",
    "for feature in features: # for each feature we wait for a valid response, and we add that to our dictionary\n",
    "    valid = True\n",
    "    val = input(f\"{feature}: \") # take user input of feature value\n",
    "    predict[feature] = [float(val)] #values to predict must be in a lsit for tensorflow. We assemble the keys and values in the dictionary. \n",
    "    # {predict[feature]:[float(val)]}\n",
    "\n",
    "predictions = classifier.predict(input_fn=lambda: input_function(predict)) # every prediction comes as dictionary\n",
    "for pred_dict in predictions:\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id] # get accuracy of prediction\n",
    "\n",
    "    print(f'Prediction is {SPECIES[class_id]}, {100 * probability}%')\n",
    "    print(pred_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
